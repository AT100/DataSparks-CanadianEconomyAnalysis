AWS EMR + S3 Setup Guidelines :
==========================

 AWS Educate Account : [Pipeline : EMR Spark Cluster --> S3 storage --> Visualization]
------------------------------------
------------------------------------

1. AWS Console Details :
---------------------------------------
Key Pair Created - "datasparks"
Files for key pairs:
-> "DataSparks.pem" --- for linux/mac
-> "dataKey.ppk" --- converted by PuttyGen for Windows

[ EXTRA : Custom password for AWS Management Console Access --> "data123#" ]

Note : 
--------

### S3 Storage Bucket ###
-> A bucket called "mysparks" has been created which contains 3 csv IMF data files and 1 py file [For testing]
-> To be Done : Reorganize the "mysparks" bucket into 3 folders -> input data, codes, and output data
-> Later on, upload to git and link to EMR Cluster

### EMR Cluster ###
-> **** Create a new cluster for every session and terminate before 1hr to avoid cost of EMR ****
-> For Windows :
----> Open Putty, copy HostName from EMR SSH, save session, and connect via "Auth->Browse->dataKey.ppk file", and then
         open the session to connect to putty Ec2 terminal
-----> Once the terminal opens, enter the EMR PassPhrase --- "data" to login to the session
------> Note : A folder "demo1" has been created, which currenlty stores the test py file "demo1.py"
-------> To move files from the s3 bucket to the ec2 terminal folder :
            aws s3 cp s3://mysparks/filename.extension
------> "cd demo1" ----> spark-submit demo1.py (view the results)

### MatplotLib / Seaborn Visualization ###  [Note -> AWS QuickSight isnt free for AWS Educate Account]
-> To produce visualization dashboards
